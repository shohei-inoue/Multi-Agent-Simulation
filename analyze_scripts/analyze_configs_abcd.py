#!/usr/bin/env python3
"""
Config_Aã€Bã€Cã€Dã®æ¯”è¼ƒåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
éšœå®³ç‰©å¯†åº¦0.003ã®çµæœã‚’æ¯”è¼ƒ
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from typing import Dict, List, Any
import os

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
import matplotlib.font_manager as fm

# åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¤œç´¢
japanese_fonts = ['Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP', 'DejaVu Sans']
available_font = None

for font in japanese_fonts:
    try:
        fm.findfont(font)
        available_font = font
        break
    except:
        continue

if available_font:
    plt.rcParams['font.family'] = available_font
    print(f"ä½¿ç”¨ãƒ•ã‚©ãƒ³ãƒˆ: {available_font}")
else:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š
    plt.rcParams['font.family'] = ['DejaVu Sans', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']
    print("è­¦å‘Š: æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

plt.rcParams['axes.unicode_minus'] = False

def load_verification_result(file_path: str) -> Dict[str, Any]:
    """æ¤œè¨¼çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def load_step_data(config_name: str, episode: int, log_dir: str) -> pd.DataFrame:
    """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã”ã¨ã®stepãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
    csv_path = os.path.join(log_dir, "csvs", f"episode_{episode:04d}_exploration.csv")
    try:
        df = pd.read_csv(csv_path)
        return df
    except FileNotFoundError:
        print(f"è­¦å‘Š: {csv_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return pd.DataFrame()

def calculate_exploration_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """æ¢æŸ»ç‡ã®è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—"""
    if df.empty:
        return {}
    
    # æ¢æŸ»ç‡ã®å¤‰åŒ–ç‡ã‚’è¨ˆç®—
    df['exploration_rate_change'] = df['exploration_rate'].diff()
    df['exploration_rate_change_rate'] = df['exploration_rate_change'] / df['exploration_rate'].shift(1)
    df['exploration_rate_change_rate'] = df['exploration_rate_change_rate'].fillna(0)
    
    # æ–°ã—ãæ¢æŸ»ã•ã‚ŒãŸã‚¨ãƒªã‚¢æ•°ã‚’è¨ˆç®—
    df['new_explored_area'] = df['explored_area'].diff()
    df['new_explored_area'] = df['new_explored_area'].fillna(0)
    
    # æ¢æŸ»åŠ¹ç‡ï¼ˆæ–°ã—ãæ¢æŸ»ã•ã‚ŒãŸã‚¨ãƒªã‚¢æ•°/ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
    df['exploration_efficiency'] = df['new_explored_area'] / df['total_area']
    
    # ç›®æ¨™æ¢æŸ»ç‡ï¼ˆä¾‹ï¼š0.8ï¼‰ã¸ã®åˆ°é”é€Ÿåº¦
    target_rate = 0.8
    target_reached_steps = df[df['exploration_rate'] >= target_rate]
    target_reaching_speed = len(target_reached_steps) if not target_reached_steps.empty else None
    
    # æ¢æŸ»ç‡ã®ä¸€è²«æ€§ï¼ˆæ¨™æº–åå·®ï¼‰
    exploration_consistency = df['exploration_rate'].std()
    
    # å¹³å‡æ¢æŸ»åŠ¹ç‡
    avg_exploration_efficiency = df['exploration_efficiency'].mean()
    
    # æ¢æŸ»ç‡ã®æœ€å¤§å¢—åŠ ç‡
    max_exploration_increase = df['exploration_rate_change'].max()
    
    return {
        'step_data': df,
        'target_reaching_speed': target_reaching_speed,
        'exploration_consistency': exploration_consistency,
        'avg_exploration_efficiency': avg_exploration_efficiency,
        'max_exploration_increase': max_exploration_increase,
        'total_steps': len(df),
        'final_exploration_rate': df['exploration_rate'].iloc[-1] if not df.empty else 0.0
    }

def calculate_summary_stats(episodes: List[Dict]) -> Dict[str, Any]:
    """ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰çµ±è¨ˆã‚’è¨ˆç®—"""
    exploration_rates = [ep['final_exploration_rate'] for ep in episodes]
    steps_taken = [ep['steps_taken'] for ep in episodes]
    target_reached = [ep['steps_to_target'] is not None for ep in episodes]
    
    return {
        'total_episodes': len(episodes),
        'target_reached_episodes': sum(target_reached),
        'average_exploration_rate': np.mean(exploration_rates),
        'average_steps_taken': np.mean(steps_taken),
        'std_exploration_rate': np.std(exploration_rates),
        'std_steps_taken': np.std(steps_taken),
        'min_exploration_rate': np.min(exploration_rates),
        'max_exploration_rate': np.max(exploration_rates)
    }

def analyze_configs():
    """Config_Aã€Bã€Cã€Dã®æ¯”è¼ƒåˆ†æ"""
    
    # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    config_files = {
        'Config_A': 'verification_results/Config_A_obstacle_0.003/verification_result.json',
        'Config_B': 'verification_results/Config_B_obstacle_0.003/verification_result.json',
        'Config_C': 'verification_results/Config_E_obstacle_0.003/verification_result.json',  # Config_Cã¯Eã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹
        'Config_D': 'verification_results/Config_D_obstacle_0.003/verification_result.json'
    }
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    output_dir = "config_results"
    os.makedirs(output_dir, exist_ok=True)
    
    # å„Configã®çµæœã‚’èª­ã¿è¾¼ã¿
    results = {}
    step_analysis_results = {}
    
    for config_name, file_path in config_files.items():
        try:
            data = load_verification_result(file_path)
            episodes = data['episodes']
            
            # summaryãŒå­˜åœ¨ã—ãªã„å ´åˆã¯è¨ˆç®—
            if 'summary' in data:
                summary = data['summary']
                # ä¸è¶³ã—ã¦ã„ã‚‹çµ±è¨ˆå€¤ã‚’è¿½åŠ 
                if 'min_exploration_rate' not in summary:
                    exploration_rates = [ep['final_exploration_rate'] for ep in episodes]
                    summary['min_exploration_rate'] = np.min(exploration_rates)
                    summary['max_exploration_rate'] = np.max(exploration_rates)
            else:
                summary = calculate_summary_stats(episodes)
            
            # Config_Cã®å ´åˆã¯ã€å®Ÿéš›ã®Configåã‚’Eã‹ã‚‰Cã«å¤‰æ›´
            display_name = config_name
            if config_name == 'Config_C':
                display_name = 'Config_C'  # è¡¨ç¤ºç”¨ã®åå‰ã‚’Cã«çµ±ä¸€
            
            results[display_name] = {
                'episodes': episodes,
                'summary': summary,
                'environment': data['environment']
            }
            
            # Stepã”ã¨ã®è©³ç´°åˆ†æ
            step_analysis = analyze_step_data(display_name, episodes, data['environment'])
            step_analysis_results[display_name] = step_analysis
            
            print(f"âœ“ {display_name} ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†")
            
        except Exception as e:
            print(f"âŒ {config_name} ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # æ¯”è¼ƒè¡¨ã‚’ä½œæˆ
    print("\n=== Configæ¯”è¼ƒçµæœ (éšœå®³ç‰©å¯†åº¦: 0.003) ===")
    print(f"{'Config':<10} {'å¹³å‡æ¢æŸ»ç‡':<12} {'æ¨™æº–åå·®':<12} {'ç›®æ¨™é”æˆç‡':<12} {'æœ€å°å€¤':<10} {'æœ€å¤§å€¤':<10}")
    print("-" * 80)
    
    comparison_data = []
    for config_name, data in results.items():
        summary = data['summary']
        avg_rate = summary['average_exploration_rate']
        std_rate = summary['std_exploration_rate']
        target_rate = summary['target_reached_episodes'] / summary['total_episodes'] * 100
        min_rate = summary['min_exploration_rate']
        max_rate = summary['max_exploration_rate']
        
        print(f"{config_name:<10} {avg_rate:.3f}Â±{std_rate:.3f} {'':<4} {target_rate:.1f}% {'':<8} {min_rate:.3f} {'':<7} {max_rate:.3f}")
        
        comparison_data.append({
            'Config': config_name,
            'Average_Exploration_Rate': avg_rate,
            'Std_Exploration_Rate': std_rate,
            'Target_Achievement_Rate': target_rate,
            'Min_Exploration_Rate': min_rate,
            'Max_Exploration_Rate': max_rate
        })
    
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    df = pd.DataFrame(comparison_data)
    csv_path = os.path.join(output_dir, "config_comparison_results.csv")
    df.to_csv(csv_path, index=False, encoding='utf-8')
    print(f"\nâœ“ æ¯”è¼ƒçµæœã‚’ä¿å­˜: {csv_path}")
    
    # å¯è¦–åŒ–
    create_comparison_plots(results, output_dir)
    
    # Stepã”ã¨ã®è©³ç´°åˆ†æçµæœã‚’å¯è¦–åŒ–
    create_step_analysis_plots(step_analysis_results, output_dir)
    
    return results, step_analysis_results

def analyze_step_data(config_name: str, episodes: List[Dict], environment: Dict) -> Dict[str, Any]:
    """Stepã”ã¨ã®è©³ç´°åˆ†æ"""
    step_metrics = {
        'config_name': config_name,
        'episodes': [],
        'avg_exploration_curves': [],
        'exploration_efficiency': [],
        'target_reaching_speeds': []
    }
    
    # å„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã®stepãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ
    for episode in episodes:
        episode_num = episode.get('episode', 0)
        
        # ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç‰¹å®š
        log_dir = f"verification_results/{config_name}_obstacle_0.003"
        
        # Stepãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        step_df = load_step_data(config_name, episode_num, log_dir)
        
        if not step_df.empty:
            # æ¢æŸ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’è¨ˆç®—
            metrics = calculate_exploration_metrics(step_df)
            
            step_metrics['episodes'].append({
                'episode': episode_num,
                'step_data': step_df,
                'metrics': metrics
            })
            
            # å¹³å‡å€¤ã®è¨ˆç®—ç”¨ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
            if 'step_data' in metrics and not metrics['step_data'].empty:
                step_metrics['avg_exploration_curves'].append(metrics['step_data']['exploration_rate'].values)
                step_metrics['exploration_efficiency'].append(metrics['avg_exploration_efficiency'])
                if metrics['target_reaching_speed'] is not None:
                    step_metrics['target_reaching_speeds'].append(metrics['target_reaching_speed'])
    
    # å¹³å‡å€¤ã‚’è¨ˆç®—
    if step_metrics['avg_exploration_curves']:
        # æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°ã«åˆã‚ã›ã¦æ­£è¦åŒ–
        max_steps = max(len(curve) for curve in step_metrics['avg_exploration_curves'])
        normalized_curves = []
        
        for curve in step_metrics['avg_exploration_curves']:
            if len(curve) < max_steps:
                # æœ€å¾Œã®å€¤ã‚’ç¹°ã‚Šè¿”ã—ã¦æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°ã«åˆã‚ã›ã‚‹
                extended_curve = np.pad(curve, (0, max_steps - len(curve)), mode='edge')
                normalized_curves.append(extended_curve)
            else:
                normalized_curves.append(curve)
        
        step_metrics['avg_exploration_curve'] = np.mean(normalized_curves, axis=0)
        step_metrics['std_exploration_curve'] = np.std(normalized_curves, axis=0)
    
    step_metrics['avg_exploration_efficiency'] = np.mean(step_metrics['exploration_efficiency']) if step_metrics['exploration_efficiency'] else 0.0
    step_metrics['avg_target_reaching_speed'] = np.mean(step_metrics['target_reaching_speeds']) if step_metrics['target_reaching_speeds'] else None
    
    return step_metrics

def create_comparison_plots(results: Dict[str, Any], output_dir: str):
    """æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä½œæˆ"""
    
    # 1. å¹³å‡æ¢æŸ»ç‡ã®æ¯”è¼ƒ
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # å¹³å‡æ¢æŸ»ç‡ã¨æ¨™æº–åå·®
    configs = list(results.keys())
    avg_rates = [results[config]['summary']['average_exploration_rate'] for config in configs]
    std_rates = [results[config]['summary']['std_exploration_rate'] for config in configs]
    
    bars = ax1.bar(configs, avg_rates, yerr=std_rates, capsize=5, alpha=0.7)
    ax1.set_title('å¹³å‡æ¢æŸ»ç‡æ¯”è¼ƒ')
    ax1.set_ylabel('æ¢æŸ»ç‡')
    ax1.set_ylim(0, 1)
    
    # ãƒãƒ¼ã®è‰²ã‚’è¨­å®š
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
    for bar, color in zip(bars, colors):
        bar.set_color(color)
    
    # 2. æ¢æŸ»ç‡åˆ†å¸ƒã®ç®±ã²ã’å›³
    exploration_data = []
    for config in configs:
        rates = [ep['final_exploration_rate'] for ep in results[config]['episodes']]
        exploration_data.append(rates)
    
    bp = ax2.boxplot(exploration_data, labels=configs, patch_artist=True)
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.7)
    ax2.set_title('æ¢æŸ»ç‡åˆ†å¸ƒ')
    ax2.set_ylabel('æ¢æŸ»ç‡')
    ax2.set_ylim(0, 1)
    
    # 3. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é€²è¡Œã«ã‚ˆã‚‹æ¢æŸ»ç‡å¤‰åŒ–
    for i, config in enumerate(configs):
        episodes = results[config]['episodes']
        rates = [ep['final_exploration_rate'] for ep in episodes]
        ax3.plot(range(1, len(rates) + 1), rates, 
                label=config, color=colors[i], alpha=0.7, linewidth=1)
    
    ax3.set_title('ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é€²è¡Œã«ã‚ˆã‚‹æ¢æŸ»ç‡å¤‰åŒ–')
    ax3.set_xlabel('ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰')
    ax3.set_ylabel('æ¢æŸ»ç‡')
    ax3.legend()
    ax3.grid(True, alpha=0.3)
    
    # 4. ç›®æ¨™é”æˆç‡ã®æ¯”è¼ƒ
    target_rates = []
    for config in configs:
        summary = results[config]['summary']
        target_rate = summary['target_reached_episodes'] / summary['total_episodes'] * 100
        target_rates.append(target_rate)
    
    bars = ax4.bar(configs, target_rates, color=colors, alpha=0.7)
    ax4.set_title('ç›®æ¨™é”æˆç‡æ¯”è¼ƒ')
    ax4.set_ylabel('é”æˆç‡ (%)')
    ax4.set_ylim(0, 100)
    
    # ãƒãƒ¼ã«å€¤ã‚’è¡¨ç¤º
    for bar, rate in zip(bars, target_rates):
        height = bar.get_height()
        ax4.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{rate:.1f}%', ha='center', va='bottom')
    
    plt.tight_layout()
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    plot_path = os.path.join(output_dir, "config_comparison_analysis.png")
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {plot_path}")
    
    # çµ±è¨ˆçš„æ¤œå®š
    perform_statistical_tests(results, output_dir)

def create_step_analysis_plots(step_analysis_results: Dict[str, Any], output_dir: str):
    """Stepã”ã¨ã®è©³ç´°åˆ†æçµæœã‚’å¯è¦–åŒ–"""
    
    # 1. æ¢æŸ»ç‡ã®æ™‚é–“å¤‰åŒ–ï¼ˆå¹³å‡ï¼‰
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    configs = list(step_analysis_results.keys())
    colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
    
    # æ¢æŸ»ç‡ã®æ™‚é–“å¤‰åŒ–
    for i, config in enumerate(configs):
        if 'avg_exploration_curve' in step_analysis_results[config]:
            curve = step_analysis_results[config]['avg_exploration_curve']
            std_curve = step_analysis_results[config]['std_exploration_curve']
            steps = range(1, len(curve) + 1)
            
            ax1.plot(steps, curve, label=config, color=colors[i], linewidth=2)
            ax1.fill_between(steps, curve - std_curve, curve + std_curve, 
                           alpha=0.3, color=colors[i])
    
    ax1.set_title('æ¢æŸ»ç‡ã®æ™‚é–“å¤‰åŒ–ï¼ˆå¹³å‡ï¼‰')
    ax1.set_xlabel('ã‚¹ãƒ†ãƒƒãƒ—')
    ax1.set_ylabel('æ¢æŸ»ç‡')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # 2. æ¢æŸ»åŠ¹ç‡ã®æ¯”è¼ƒ
    efficiency_data = []
    efficiency_labels = []
    for config in configs:
        if 'avg_exploration_efficiency' in step_analysis_results[config]:
            efficiency = step_analysis_results[config]['avg_exploration_efficiency']
            efficiency_data.append(efficiency)
            efficiency_labels.append(config)
    
    if efficiency_data:
        bars = ax2.bar(efficiency_labels, efficiency_data, color=colors[:len(efficiency_data)], alpha=0.7)
        ax2.set_title('å¹³å‡æ¢æŸ»åŠ¹ç‡æ¯”è¼ƒ')
        ax2.set_ylabel('æ¢æŸ»åŠ¹ç‡')
        
        # ãƒãƒ¼ã«å€¤ã‚’è¡¨ç¤º
        for bar, value in zip(bars, efficiency_data):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height + 0.001,
                    f'{value:.4f}', ha='center', va='bottom')
    
    # 3. ç›®æ¨™åˆ°é”é€Ÿåº¦ã®æ¯”è¼ƒ
    speed_data = []
    speed_labels = []
    for config in configs:
        if 'avg_target_reaching_speed' in step_analysis_results[config]:
            speed = step_analysis_results[config]['avg_target_reaching_speed']
            if speed is not None:
                speed_data.append(speed)
                speed_labels.append(config)
    
    if speed_data:
        bars = ax3.bar(speed_labels, speed_data, color=colors[:len(speed_data)], alpha=0.7)
        ax3.set_title('ç›®æ¨™åˆ°é”é€Ÿåº¦æ¯”è¼ƒ')
        ax3.set_ylabel('åˆ°é”ã‚¹ãƒ†ãƒƒãƒ—æ•°')
        
        # ãƒãƒ¼ã«å€¤ã‚’è¡¨ç¤º
        for bar, value in zip(bars, speed_data):
            height = bar.get_height()
            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                    f'{value:.0f}', ha='center', va='bottom')
    
    # 4. æ¢æŸ»ç‡ã®å¤‰åŒ–ç‡åˆ†å¸ƒ
    for i, config in enumerate(configs):
        if 'episodes' in step_analysis_results[config]:
            all_changes = []
            for episode_data in step_analysis_results[config]['episodes']:
                if 'step_data' in episode_data['metrics']:
                    df = episode_data['metrics']['step_data']
                    if 'exploration_rate_change' in df.columns:
                        changes = df['exploration_rate_change'].dropna()
                        all_changes.extend(changes)
            
            if all_changes:
                ax4.hist(all_changes, bins=20, alpha=0.7, label=config, color=colors[i])
    
    ax4.set_title('æ¢æŸ»ç‡å¤‰åŒ–ç‡ã®åˆ†å¸ƒ')
    ax4.set_xlabel('æ¢æŸ»ç‡å¤‰åŒ–é‡')
    ax4.set_ylabel('é »åº¦')
    ax4.legend()
    ax4.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    plot_path = os.path.join(output_dir, "step_analysis_comparison.png")
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ Stepåˆ†æã‚°ãƒ©ãƒ•ã‚’ä¿å­˜: {plot_path}")
    
    # Stepåˆ†æçµæœã‚’CSVã¨ã—ã¦ä¿å­˜
    step_summary_data = []
    for config in configs:
        if 'avg_exploration_efficiency' in step_analysis_results[config]:
            summary = {
                'Config': config,
                'Avg_Exploration_Efficiency': step_analysis_results[config]['avg_exploration_efficiency'],
                'Avg_Target_Reaching_Speed': step_analysis_results[config].get('avg_target_reaching_speed', None),
                'Total_Episodes_Analyzed': len(step_analysis_results[config]['episodes'])
            }
            step_summary_data.append(summary)
    
    if step_summary_data:
        step_df = pd.DataFrame(step_summary_data)
        step_csv_path = os.path.join(output_dir, "step_analysis_summary.csv")
        step_df.to_csv(step_csv_path, index=False, encoding='utf-8')
        print(f"âœ“ Stepåˆ†æã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜: {step_csv_path}")

def perform_statistical_tests(results: Dict[str, Any], output_dir: str):
    """çµ±è¨ˆçš„æ¤œå®šã‚’å®Ÿè¡Œ"""
    from scipy import stats
    
    print(f"\n=== çµ±è¨ˆçš„æ¤œå®šçµæœ ===")
    
    # å„Configã®æ¢æŸ»ç‡ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    config_data = {}
    for config_name, data in results.items():
        rates = [ep['final_exploration_rate'] for ep in data['episodes']]
        config_data[config_name] = rates
    
    # ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æï¼ˆANOVAï¼‰
    configs = list(config_data.keys())
    f_stat, p_value = stats.f_oneway(*[config_data[config] for config in configs])
    
    print(f"ä¸€å…ƒé…ç½®åˆ†æ•£åˆ†æï¼ˆANOVAï¼‰:")
    print(f"  Fçµ±è¨ˆé‡: {f_stat:.4f}")
    print(f"  på€¤: {p_value:.4f}")
    print(f"  æœ‰æ„å·®: {'ã‚ã‚Š' if p_value < 0.05 else 'ãªã—'}")
    
    # ãƒšã‚¢ãƒ¯ã‚¤ã‚ºæ¯”è¼ƒï¼ˆTukeyæ¤œå®šï¼‰
    try:
        from statsmodels.stats.multicomp import pairwise_tukeyhsd
        all_rates = []
        all_configs = []
        for config in configs:
            all_rates.extend(config_data[config])
            all_configs.extend([config] * len(config_data[config]))
        
        tukey = pairwise_tukeyhsd(all_rates, all_configs)
        print(f"\nTukeyæ¤œå®šçµæœ:")
        print(tukey)
        
        # Tukeyæ¤œå®šçµæœã‚’CSVã¨ã—ã¦ä¿å­˜
        tukey_df = pd.DataFrame(tukey._results_table.data[1:], columns=tukey._results_table.data[0])
        tukey_path = os.path.join(output_dir, "tukey_test_results.csv")
        tukey_df.to_csv(tukey_path, index=False, encoding='utf-8')
        print(f"âœ“ Tukeyæ¤œå®šçµæœã‚’ä¿å­˜: {tukey_path}")
        
    except ImportError:
        print("statsmodelsãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€Tukeyæ¤œå®šã‚’ã‚¹ã‚­ãƒƒãƒ—")
    
    # åŠ¹æœé‡ï¼ˆCohen's dï¼‰ã®è¨ˆç®—
    print(f"\nåŠ¹æœé‡ï¼ˆCohen's dï¼‰:")
    effect_sizes = []
    for i in range(len(configs)):
        for j in range(i + 1, len(configs)):
            config1, config2 = configs[i], configs[j]
            d = (np.mean(config_data[config1]) - np.mean(config_data[config2])) / np.sqrt(
                ((len(config_data[config1]) - 1) * np.var(config_data[config1], ddof=1) + 
                 (len(config_data[config2]) - 1) * np.var(config_data[config2], ddof=1)) / 
                (len(config_data[config1]) + len(config_data[config2]) - 2)
            )
            print(f"  {config1} vs {config2}: {d:.3f}")
            effect_sizes.append({
                'Config1': config1,
                'Config2': config2,
                'Cohen_d': d
            })
    
    # åŠ¹æœé‡ã‚’CSVã¨ã—ã¦ä¿å­˜
    effect_df = pd.DataFrame(effect_sizes)
    effect_path = os.path.join(output_dir, "effect_sizes.csv")
    effect_df.to_csv(effect_path, index=False, encoding='utf-8')
    print(f"âœ“ åŠ¹æœé‡ã‚’ä¿å­˜: {effect_path}")

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=== Config_Aã€Bã€Cã€Dæ¯”è¼ƒåˆ†æé–‹å§‹ ===")
    
    try:
        results, step_analysis_results = analyze_configs()
        print(f"\nğŸ‰ åˆ†æãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
        print(f"çµæœã¯ 'config_results' ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
        
    except Exception as e:
        print(f"âŒ åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 