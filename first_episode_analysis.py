#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
First Episode Analysis Script
å„Configã®1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã®ã¿ã‚’æŠ½å‡ºã—ã¦æ¯”è¼ƒåˆ†æžã™ã‚‹

ä½¿ç”¨æ–¹æ³•:
    python first_episode_analysis.py

å‡ºåŠ›:
    - first_episode_analysis_results/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«çµæžœã‚’ä¿å­˜
    - PNGå½¢å¼ã®ã‚°ãƒ©ãƒ•
    - CSVå½¢å¼ã®çµ±è¨ˆãƒ‡ãƒ¼ã‚¿
"""

import os
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Any
from scipy import stats

# æ—¥æœ¬èªžãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.style.use('default')

class FirstEpisodeAnalyzer:
    def __init__(self, data_dir: str = "verify_configs/verification_results"):
        """
        åˆæœŸåŒ–
        
        Args:
            data_dir: æ¤œè¨¼çµæžœãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        self.data_dir = Path(data_dir)
        self.first_episode_data = pd.DataFrame()
        self.step_data = pd.DataFrame()
        
    def load_first_episode_data(self) -> bool:
        """
        å„Configã®1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        
        Returns:
            bool: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸå¯å¦
        """
        print("=== 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ ===")
        
        if not self.data_dir.exists():
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {self.data_dir}")
            return False
        
        episode_records = []
        step_records = []
        
        # å„Configãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŽ¢ç´¢
        for config_dir in self.data_dir.iterdir():
            if not config_dir.is_dir():
                continue
                
            config_name = config_dir.name
            print(f"  ðŸ“‚ {config_name} ã‚’å‡¦ç†ä¸­...")
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŽ¢ç´¢
            json_files = list(config_dir.glob("*.json"))
            if not json_files:
                print(f"    âš ï¸  JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                continue
            
            for json_file in json_files:
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿æŠ½å‡º
                    episodes_data = None
                    if isinstance(data, dict) and 'episodes' in data:
                        episodes_data = data['episodes']
                    elif isinstance(data, list):
                        episodes_data = data
                    
                    if episodes_data and len(episodes_data) > 0:
                        first_episode = episodes_data[0]  # æœ€åˆã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰
                        
                        # åŸºæœ¬æƒ…å ±ã‚’æŠ½å‡º
                        episode_info = {
                            'config_type': config_name.split('_')[2].upper(),  # A, B, C, D
                            'obstacle_density': float(config_name.split('_')[3]),
                            'episode_id': first_episode.get('episode', 1),
                            'final_exploration_rate': first_episode.get('final_exploration_rate', 0.0),
                            'steps_taken': first_episode.get('steps_taken', 0),
                            'steps_to_target': first_episode.get('steps_to_target', None),
                            'total_reward': first_episode.get('total_reward', 0.0),
                            'avg_reward': first_episode.get('avg_reward', 0.0),
                            'file_source': json_file.name
                        }
                        episode_records.append(episode_info)
                        
                        # ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                        if 'step_details' in first_episode:
                            for step_detail in first_episode['step_details']:
                                step_info = {
                                    'config_type': config_name.split('_')[2].upper(),
                                    'obstacle_density': float(config_name.split('_')[3]),
                                    'episode_id': first_episode.get('episode', 1),
                                    'step_id': step_detail.get('step', 0),
                                    'exploration_rate': step_detail.get('exploration_rate', 0.0),
                                    'reward': step_detail.get('reward', 0.0),
                                    'swarm_count': step_detail.get('swarm_count', 1),
                                    'agent_collision_flag': step_detail.get('agent_collision_flag', 0),
                                    'follower_collision_count': step_detail.get('follower_collision_count', 0),
                                    'file_source': json_file.name
                                }
                                step_records.append(step_info)
                    
                    print(f"    âœ“ {json_file.name} å‡¦ç†å®Œäº†")
                    
                except Exception as e:
                    print(f"    âŒ {json_file.name} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
        
        # DataFrameã«å¤‰æ›
        if episode_records:
            self.first_episode_data = pd.DataFrame(episode_records)
            print(f"âœ“ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿: {len(self.first_episode_data)} ä»¶")
        else:
            print("âŒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            
        if step_records:
            self.step_data = pd.DataFrame(step_records)
            print(f"âœ“ ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿: {len(self.step_data)} ä»¶")
        else:
            print("âŒ ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        return len(episode_records) > 0
    
    def generate_comparison_plots(self, output_dir: str = "first_episode_analysis_results"):
        """
        1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆ
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        print("=== 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®æ¯”è¼ƒã‚°ãƒ©ãƒ•ç”Ÿæˆä¸­ ===")
        
        os.makedirs(output_dir, exist_ok=True)
        
        if self.first_episode_data.empty:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã€ã‚°ãƒ©ãƒ•ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            return
        
        # 1. åŸºæœ¬æ¯”è¼ƒã‚°ãƒ©ãƒ•
        plt.figure(figsize=(16, 12))
        
        # 1-1. Configåˆ¥æœ€çµ‚æŽ¢æŸ»çŽ‡
        plt.subplot(2, 3, 1)
        config_exploration = self.first_episode_data.groupby('config_type')['final_exploration_rate'].mean()
        config_exploration.plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])
        plt.title('Final Exploration Rate by Config (Episode 1)')
        plt.xlabel('Config Type')
        plt.ylabel('Final Exploration Rate')
        plt.xticks(rotation=0)
        plt.grid(True, alpha=0.3)
        
        # 1-2. Configåˆ¥ã‚¹ãƒ†ãƒƒãƒ—æ•°
        plt.subplot(2, 3, 2)
        config_steps = self.first_episode_data.groupby('config_type')['steps_taken'].mean()
        config_steps.plot(kind='bar', color=['lightsteelblue', 'lightpink', 'lightseagreen', 'lightyellow'])
        plt.title('Steps Taken by Config (Episode 1)')
        plt.xlabel('Config Type')
        plt.ylabel('Steps Taken')
        plt.xticks(rotation=0)
        plt.grid(True, alpha=0.3)
        
        # 1-3. éšœå®³ç‰©å¯†åº¦åˆ¥ã®å½±éŸ¿
        plt.subplot(2, 3, 3)
        density_exploration = self.first_episode_data.groupby('obstacle_density')['final_exploration_rate'].mean()
        density_exploration.plot(kind='bar', color=['lightblue', 'orange', 'lightcoral'])
        plt.title('Final Exploration Rate by Obstacle Density (Episode 1)')
        plt.xlabel('Obstacle Density')
        plt.ylabel('Final Exploration Rate')
        plt.xticks(rotation=0)
        plt.grid(True, alpha=0.3)
        
        # 1-4. ConfigÃ—éšœå®³ç‰©å¯†åº¦ã®ãƒ’ãƒ¼ãƒˆãƒžãƒƒãƒ—
        plt.subplot(2, 3, 4)
        if len(self.first_episode_data) > 1:
            pivot_data = self.first_episode_data.pivot_table(
                values='final_exploration_rate', 
                index='config_type', 
                columns='obstacle_density', 
                aggfunc='mean'
            )
            sns.heatmap(pivot_data, annot=True, fmt='.3f', cmap='YlOrRd')
            plt.title('Exploration Rate Heatmap (Episode 1)')
        
        # 1-5. æŽ¢æŸ»çŽ‡åˆ†å¸ƒï¼ˆç®±ã²ã’å›³ï¼‰
        plt.subplot(2, 3, 5)
        config_types = sorted(self.first_episode_data['config_type'].unique())
        exploration_data = []
        labels = []
        
        for config_type in config_types:
            config_data = self.first_episode_data[
                self.first_episode_data['config_type'] == config_type
            ]['final_exploration_rate'].values
            exploration_data.append(config_data)
            labels.append(f'Config {config_type}')
        
        if exploration_data:
            plt.boxplot(exploration_data, labels=labels)
            plt.title('Exploration Rate Distribution by Config (Episode 1)')
            plt.ylabel('Final Exploration Rate')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
        
        # 1-6. æŽ¢æŸ»çŽ‡ vs ã‚¹ãƒ†ãƒƒãƒ—æ•°ã®æ•£å¸ƒå›³
        plt.subplot(2, 3, 6)
        colors = {'A': 'blue', 'B': 'red', 'C': 'green', 'D': 'orange'}
        for config_type in self.first_episode_data['config_type'].unique():
            config_df = self.first_episode_data[self.first_episode_data['config_type'] == config_type]
            plt.scatter(config_df['steps_taken'], 
                       config_df['final_exploration_rate'],
                       c=colors.get(config_type, 'gray'),
                       label=f'Config {config_type}',
                       alpha=0.7, s=100)
        
        plt.xlabel('Steps Taken')
        plt.ylabel('Final Exploration Rate')
        plt.title('Exploration Rate vs Steps (Episode 1)')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/first_episode_comparison.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°åˆ†æžï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
        if not self.step_data.empty:
            self.generate_step_analysis(output_dir)
        
        print(f"âœ“ æ¯”è¼ƒã‚°ãƒ©ãƒ•ã‚’ {output_dir}/ ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def generate_step_analysis(self, output_dir: str):
        """
        1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã®ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°åˆ†æž
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        plt.figure(figsize=(16, 10))
        
        # 2-1. ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®æŽ¢æŸ»çŽ‡å¤‰åŒ–
        plt.subplot(2, 3, 1)
        colors = {'A': 'blue', 'B': 'red', 'C': 'green', 'D': 'orange'}
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            avg_exploration_by_step = config_steps.groupby('step_id')['exploration_rate'].mean()
            plt.plot(avg_exploration_by_step.index, avg_exploration_by_step.values, 
                    color=colors.get(config_type, 'gray'),
                    label=f'Config {config_type}', linewidth=2, marker='o', markersize=3)
        
        plt.title('Exploration Rate Progress (Episode 1)')
        plt.xlabel('Step')
        plt.ylabel('Exploration Rate')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2-2. ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®å ±é…¬å¤‰åŒ–
        plt.subplot(2, 3, 2)
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            avg_reward_by_step = config_steps.groupby('step_id')['reward'].mean()
            plt.plot(avg_reward_by_step.index, avg_reward_by_step.values, 
                    color=colors.get(config_type, 'gray'),
                    label=f'Config {config_type}', linewidth=2, marker='s', markersize=3)
        
        plt.title('Reward Progress (Episode 1)')
        plt.xlabel('Step')
        plt.ylabel('Average Reward')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2-3. ã‚¹ãƒ¯ãƒ¼ãƒ æ•°ã®å¤‰åŒ–
        plt.subplot(2, 3, 3)
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            avg_swarms_by_step = config_steps.groupby('step_id')['swarm_count'].mean()
            plt.plot(avg_swarms_by_step.index, avg_swarms_by_step.values, 
                    color=colors.get(config_type, 'gray'),
                    label=f'Config {config_type}', linewidth=2, marker='^', markersize=3)
        
        plt.title('Swarm Count Progress (Episode 1)')
        plt.xlabel('Step')
        plt.ylabel('Average Swarm Count')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2-4. è¡çªç™ºç”ŸçŽ‡
        plt.subplot(2, 3, 4)
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            collision_rate_by_step = config_steps.groupby('step_id')['agent_collision_flag'].mean()
            plt.plot(collision_rate_by_step.index, collision_rate_by_step.values, 
                    color=colors.get(config_type, 'gray'),
                    label=f'Config {config_type}', linewidth=2, marker='x', markersize=3)
        
        plt.title('Collision Rate Progress (Episode 1)')
        plt.xlabel('Step')
        plt.ylabel('Collision Rate')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2-5. æŽ¢æŸ»åŠ¹çŽ‡ï¼ˆæŽ¢æŸ»çŽ‡/ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
        plt.subplot(2, 3, 5)
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            # æŽ¢æŸ»åŠ¹çŽ‡ã‚’è¨ˆç®—
            efficiency_data = []
            step_ids = []
            for step_id in sorted(config_steps['step_id'].unique()):
                step_data = config_steps[config_steps['step_id'] == step_id]
                if step_id > 0:  # ã‚¼ãƒ­é™¤ç®—ã‚’é¿ã‘ã‚‹
                    efficiency = step_data['exploration_rate'].mean() / step_id
                    efficiency_data.append(efficiency)
                    step_ids.append(step_id)
            
            if efficiency_data:
                plt.plot(step_ids, efficiency_data, 
                        color=colors.get(config_type, 'gray'),
                        label=f'Config {config_type}', linewidth=2, marker='d', markersize=3)
        
        plt.title('Exploration Efficiency (Episode 1)')
        plt.xlabel('Step')
        plt.ylabel('Exploration Rate / Step')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2-6. ç´¯ç©å ±é…¬
        plt.subplot(2, 3, 6)
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            cumulative_reward = config_steps.groupby('step_id')['reward'].sum().cumsum()
            plt.plot(cumulative_reward.index, cumulative_reward.values, 
                    color=colors.get(config_type, 'gray'),
                    label=f'Config {config_type}', linewidth=2)
        
        plt.title('Cumulative Reward (Episode 1)')
        plt.xlabel('Step')
        plt.ylabel('Cumulative Reward')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/first_episode_step_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
    
    def generate_statistical_analysis(self, output_dir: str = "first_episode_analysis_results"):
        """
        1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã®çµ±è¨ˆåˆ†æž
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        print("=== 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®çµ±è¨ˆåˆ†æžå®Ÿè¡Œä¸­ ===")
        
        os.makedirs(output_dir, exist_ok=True)
        
        if self.first_episode_data.empty:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return
        
        # åŸºæœ¬çµ±è¨ˆé‡
        stats_summary = []
        
        for config_type in sorted(self.first_episode_data['config_type'].unique()):
            config_data = self.first_episode_data[self.first_episode_data['config_type'] == config_type]
            
            stats_row = {
                'Config': config_type,
                'Sample_Count': len(config_data),
                'Exploration_Rate_Mean': config_data['final_exploration_rate'].mean(),
                'Exploration_Rate_Std': config_data['final_exploration_rate'].std(),
                'Exploration_Rate_Min': config_data['final_exploration_rate'].min(),
                'Exploration_Rate_Max': config_data['final_exploration_rate'].max(),
                'Steps_Mean': config_data['steps_taken'].mean(),
                'Steps_Std': config_data['steps_taken'].std(),
                'Steps_Min': config_data['steps_taken'].min(),
                'Steps_Max': config_data['steps_taken'].max(),
            }
            
            if 'total_reward' in config_data.columns:
                stats_row.update({
                    'Total_Reward_Mean': config_data['total_reward'].mean(),
                    'Total_Reward_Std': config_data['total_reward'].std(),
                })
            
            stats_summary.append(stats_row)
        
        # çµ±è¨ˆçµæžœã‚’CSVã§ä¿å­˜
        stats_df = pd.DataFrame(stats_summary)
        stats_df.to_csv(f"{output_dir}/first_episode_statistics.csv", index=False)
        
        # ANOVAåˆ†æžï¼ˆConfigé–“ã®å·®ï¼‰
        config_groups = []
        config_names = []
        
        for config_type in sorted(self.first_episode_data['config_type'].unique()):
            config_data = self.first_episode_data[
                self.first_episode_data['config_type'] == config_type
            ]['final_exploration_rate'].values
            
            if len(config_data) > 0:
                config_groups.append(config_data)
                config_names.append(config_type)
        
        if len(config_groups) > 1:
            try:
                f_stat, p_value = stats.f_oneway(*config_groups)
                anova_result = {
                    'F_statistic': f_stat,
                    'p_value': p_value,
                    'significant': p_value < 0.05
                }
                
                # ANOVAçµæžœã‚’ä¿å­˜
                with open(f"{output_dir}/first_episode_anova.json", 'w') as f:
                    json.dump(anova_result, f, indent=2)
                
                print(f"âœ“ ANOVAåˆ†æžçµæžœ: F={f_stat:.4f}, p={p_value:.4f}")
                
            except Exception as e:
                print(f"âŒ ANOVAåˆ†æžã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"âœ“ çµ±è¨ˆåˆ†æžçµæžœã‚’ {output_dir}/ ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def generate_summary_report(self, output_dir: str = "first_episode_analysis_results"):
        """
        1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã®ã‚µãƒžãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        
        Args:
            output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        """
        print("=== 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ã‚µãƒžãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ ===")
        
        os.makedirs(output_dir, exist_ok=True)
        
        if self.first_episode_data.empty:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return
        
        report_lines = []
        report_lines.append("# First Episode Analysis Report")
        report_lines.append("=" * 50)
        report_lines.append("")
        
        # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
        report_lines.append("## Data Overview")
        report_lines.append(f"- Total configurations analyzed: {len(self.first_episode_data['config_type'].unique())}")
        report_lines.append(f"- Total simulations: {len(self.first_episode_data)}")
        report_lines.append(f"- Obstacle densities: {sorted(self.first_episode_data['obstacle_density'].unique())}")
        report_lines.append("")
        
        # Configåˆ¥çµæžœ
        report_lines.append("## Results by Configuration")
        for config_type in sorted(self.first_episode_data['config_type'].unique()):
            config_data = self.first_episode_data[self.first_episode_data['config_type'] == config_type]
            
            report_lines.append(f"### Config {config_type}")
            report_lines.append(f"- Sample count: {len(config_data)}")
            report_lines.append(f"- Average exploration rate: {config_data['final_exploration_rate'].mean():.4f} Â± {config_data['final_exploration_rate'].std():.4f}")
            report_lines.append(f"- Average steps taken: {config_data['steps_taken'].mean():.1f} Â± {config_data['steps_taken'].std():.1f}")
            
            if 'total_reward' in config_data.columns:
                report_lines.append(f"- Average total reward: {config_data['total_reward'].mean():.4f} Â± {config_data['total_reward'].std():.4f}")
            
            report_lines.append("")
        
        # æœ€é«˜æ€§èƒ½
        best_exploration = self.first_episode_data.loc[self.first_episode_data['final_exploration_rate'].idxmax()]
        report_lines.append("## Best Performance")
        report_lines.append(f"- Highest exploration rate: {best_exploration['final_exploration_rate']:.4f} (Config {best_exploration['config_type']}, Density {best_exploration['obstacle_density']})")
        report_lines.append(f"- Steps taken: {best_exploration['steps_taken']}")
        report_lines.append("")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        with open(f"{output_dir}/first_episode_report.md", 'w', encoding='utf-8') as f:
            f.write('\n'.join(report_lines))
        
        print(f"âœ“ ã‚µãƒžãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ {output_dir}/ ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def run_complete_analysis(self):
        """
        å®Œå…¨ãª1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®åˆ†æžã‚’å®Ÿè¡Œ
        """
        print("ðŸš€ 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®å®Œå…¨åˆ†æžã‚’é–‹å§‹ã—ã¾ã™\n")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        if not self.load_first_episode_data():
            print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
            return False
        
        output_dir = "first_episode_analysis_results"
        
        # åˆ†æžå®Ÿè¡Œ
        self.generate_comparison_plots(output_dir)
        self.generate_statistical_analysis(output_dir)
        self.generate_summary_report(output_dir)
        
        print(f"\nðŸŽ‰ 1ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®åˆ†æžå®Œäº†ï¼")
        print(f"ðŸ“ çµæžœã¯ {output_dir}/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        
        return True


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    analyzer = FirstEpisodeAnalyzer()
    analyzer.run_complete_analysis()


if __name__ == "__main__":
    main() 