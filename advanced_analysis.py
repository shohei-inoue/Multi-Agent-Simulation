#!/usr/bin/env python3
"""
é«˜åº¦ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœè§£æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
çµ±è¨ˆçš„æ¤œå®šã€æ™‚ç³»åˆ—åˆ†æã€è©³ç´°ãªæ€§èƒ½æ¯”è¼ƒã‚’å«ã‚€åŒ…æ‹¬çš„ãªè§£æã‚’è¡Œã„ã¾ã™ã€‚
"""

import os
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from scipy import stats
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.family'] = ['DejaVu Sans', 'Hiragino Sans', 'Yu Gothic', 'Meiryo', 'Takao', 'IPAexGothic', 'IPAPGothic', 'VL PGothic', 'Noto Sans CJK JP']

class AdvancedAnalyzer:
    """é«˜åº¦ãªè§£æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, results_dir: str = "verify_configs/verification_results"):
        self.results_dir = Path(results_dir)
        self.results_data = {}
        self.episode_data = pd.DataFrame()
        self.step_data = pd.DataFrame()
        
    def load_and_process_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€è©³ç´°ãªå‡¦ç†ã‚’è¡Œã†"""
        print("=== è©³ç´°ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ ===")
        
        all_episodes = []
        all_steps = []
        
        for config_dir in self.results_dir.iterdir():
            if not config_dir.is_dir():
                continue
                
            config_name = config_dir.name
            json_file = config_dir / "verification_result.json"
            
            if not json_file.exists():
                continue
                
            print(f"å‡¦ç†ä¸­: {config_name}")
            
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # Configæƒ…å ±ã‚’æŠ½å‡º
                config_type, obstacle_density = self._extract_config_info(config_name)
                
                # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
                for episode in data.get('episodes', []):
                    episode_record = {
                        'config_name': config_name,
                        'config_type': config_type,
                        'obstacle_density': obstacle_density,
                        'episode_id': episode.get('episode', 0),
                        'final_exploration_rate': episode.get('final_exploration_rate', 0),
                        'steps_taken': episode.get('steps_taken', 0),
                        'steps_to_target': episode.get('steps_to_target'),
                    }
                    
                    # ã‚¹ãƒ†ãƒƒãƒ—è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
                    step_details = episode.get('step_details', [])
                    if step_details:
                        rewards = [step.get('reward', 0) for step in step_details]
                        exploration_rates = [step.get('exploration_rate', 0) for step in step_details]
                        
                        episode_record.update({
                            'total_reward': sum(rewards),
                            'avg_reward': np.mean(rewards),
                            'reward_std': np.std(rewards),
                            'final_reward': rewards[-1] if rewards else 0,
                            'exploration_progression': np.mean(np.diff(exploration_rates)) if len(exploration_rates) > 1 else 0,
                            'exploration_variance': np.var(exploration_rates),
                        })
                        
                        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒ‡ãƒ¼ã‚¿
                        for step_idx, step in enumerate(step_details):
                            step_record = {
                                'config_name': config_name,
                                'config_type': config_type,
                                'obstacle_density': obstacle_density,
                                'episode_id': episode.get('episode', 0),
                                'step_id': step_idx,
                                'exploration_rate': step.get('exploration_rate', 0),
                                'reward': step.get('reward', 0),
                                'done': step.get('done', False),
                                'truncated': step.get('truncated', False)
                            }
                            all_steps.append(step_record)
                    
                    all_episodes.append(episode_record)
                    
            except Exception as e:
                print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        self.episode_data = pd.DataFrame(all_episodes)
        self.step_data = pd.DataFrame(all_steps)
        
        print(f"âœ“ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿: {len(self.episode_data)} ä»¶")
        print(f"âœ“ ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿: {len(self.step_data)} ä»¶\n")
    
    def _extract_config_info(self, config_name: str) -> Tuple[str, float]:
        """Configåã‹ã‚‰è¨­å®šæƒ…å ±ã‚’æŠ½å‡º"""
        parts = config_name.replace('Config_', '').split('_obstacle_')
        config_type = parts[0]
        obstacle_density = float(parts[1]) if len(parts) > 1 else 0.0
        return config_type, obstacle_density
    
    def statistical_analysis(self, output_dir: str = "analysis_results"):
        """çµ±è¨ˆçš„åˆ†æã‚’å®Ÿè¡Œ"""
        print("=== çµ±è¨ˆçš„åˆ†æå®Ÿè¡Œä¸­ ===")
        
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ANOVAåˆ†æï¼ˆConfigé–“ã®æœ‰æ„å·®æ¤œå®šï¼‰
        print("1. ANOVAåˆ†æ")
        config_groups = []
        config_names = []
        
        for config_type in self.episode_data['config_type'].unique():
            config_data = self.episode_data[self.episode_data['config_type'] == config_type]['final_exploration_rate']
            config_groups.append(config_data.values)
            config_names.append(config_type)
        
        if len(config_groups) > 1:
            f_stat, p_value = stats.f_oneway(*config_groups)
            print(f"  Fçµ±è¨ˆé‡: {f_stat:.4f}")
            print(f"  på€¤: {p_value:.6f}")
            print(f"  æœ‰æ„å·®: {'ã‚ã‚Š' if p_value < 0.05 else 'ãªã—'}")
        
        # 2. å¯¾å¿œã®ãªã„tæ¤œå®šï¼ˆãƒšã‚¢ãƒ¯ã‚¤ã‚ºæ¯”è¼ƒï¼‰
        print("\n2. ãƒšã‚¢ãƒ¯ã‚¤ã‚ºtæ¤œå®š")
        t_test_results = []
        
        for i, config1 in enumerate(config_names):
            for config2 in config_names[i+1:]:
                data1 = self.episode_data[self.episode_data['config_type'] == config1]['final_exploration_rate']
                data2 = self.episode_data[self.episode_data['config_type'] == config2]['final_exploration_rate']
                
                t_stat, p_val = stats.ttest_ind(data1, data2)
                effect_size = (data1.mean() - data2.mean()) / np.sqrt((data1.var() + data2.var()) / 2)
                
                t_test_results.append({
                    'config1': config1,
                    'config2': config2,
                    't_statistic': t_stat,
                    'p_value': p_val,
                    'effect_size': effect_size,
                    'significant': p_val < 0.05
                })
                
                print(f"  {config1} vs {config2}: t={t_stat:.3f}, p={p_val:.4f}, effect_size={effect_size:.3f}")
        
        # çµæœã‚’CSVã§ä¿å­˜
        t_test_df = pd.DataFrame(t_test_results)
        t_test_df.to_csv(f"{output_dir}/statistical_tests.csv", index=False, encoding='utf-8')
        
        print("âœ“ çµ±è¨ˆçš„åˆ†æå®Œäº†\n")
        return t_test_results
    
    def time_series_analysis(self, output_dir: str = "analysis_results"):
        """æ™‚ç³»åˆ—åˆ†æ"""
        print("=== æ™‚ç³»åˆ—åˆ†æå®Ÿè¡Œä¸­ ===")
        
        if self.step_data.empty:
            print("âŒ ã‚¹ãƒ†ãƒƒãƒ—ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
            return
        
        plt.figure(figsize=(16, 12))
        
        # 1. æ¢æŸ»ç‡ã®æ™‚ç³»åˆ—å¤‰åŒ–
        plt.subplot(3, 2, 1)
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            avg_exploration_by_step = config_steps.groupby('step_id')['exploration_rate'].mean()
            plt.plot(avg_exploration_by_step.index, avg_exploration_by_step.values, 
                    label=f'Config {config_type}', linewidth=2, marker='o', markersize=4)
        
        plt.title('Exploration Rate Change by Step')
        plt.xlabel('Step')
        plt.ylabel('Average Exploration Rate')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. Reward Time Series Change
        plt.subplot(3, 2, 2)
        for config_type in self.step_data['config_type'].unique():
            config_steps = self.step_data[self.step_data['config_type'] == config_type]
            avg_reward_by_step = config_steps.groupby('step_id')['reward'].mean()
            plt.plot(avg_reward_by_step.index, avg_reward_by_step.values, 
                    label=f'Config {config_type}', linewidth=2, marker='s', markersize=4)
        
        plt.title('Reward Change by Step')
        plt.xlabel('Step')
        plt.ylabel('Average Reward')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 3. Learning Curves Across Episodes
        plt.subplot(3, 2, 3)
        for config_type in self.episode_data['config_type'].unique():
            config_episodes = self.episode_data[self.episode_data['config_type'] == config_type]
            avg_exploration_by_episode = config_episodes.groupby('episode_id')['final_exploration_rate'].mean()
            plt.plot(avg_exploration_by_episode.index, avg_exploration_by_episode.values, 
                    label=f'Config {config_type}', linewidth=2, alpha=0.8)
        
        plt.title('Learning Curves Across Episodes')
        plt.xlabel('Episode')
        plt.ylabel('Final Exploration Rate')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 4. Exploration Rate Variance Analysis
        plt.subplot(3, 2, 4)
        for config_type in self.episode_data['config_type'].unique():
            config_episodes = self.episode_data[self.episode_data['config_type'] == config_type]
            if 'exploration_variance' in config_episodes.columns:
                avg_variance_by_episode = config_episodes.groupby('episode_id')['exploration_variance'].mean()
                plt.plot(avg_variance_by_episode.index, avg_variance_by_episode.values, 
                        label=f'Config {config_type}', linewidth=2, linestyle='--')
        
        plt.title('Exploration Rate Variance Change')
        plt.xlabel('Episode')
        plt.ylabel('Exploration Rate Variance')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 5. Convergence Analysis
        plt.subplot(3, 2, 5)
        for config_type in self.episode_data['config_type'].unique():
            config_episodes = self.episode_data[self.episode_data['config_type'] == config_type]
            # Calculate moving average
            window_size = min(10, len(config_episodes) // 4)
            if window_size > 1:
                moving_avg = config_episodes['final_exploration_rate'].rolling(window=window_size).mean()
                plt.plot(config_episodes['episode_id'], moving_avg, 
                        label=f'Config {config_type} (Moving Avg)', linewidth=3, alpha=0.7)
        
        plt.title('Convergence Analysis (Moving Average)')
        plt.xlabel('Episode')
        plt.ylabel('Exploration Rate Moving Average')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 6. Impact of Obstacle Density
        plt.subplot(3, 2, 6)
        density_colors = {0.0: 'blue', 0.003: 'orange', 0.005: 'red'}
        for density in self.episode_data['obstacle_density'].unique():
            density_data = self.episode_data[self.episode_data['obstacle_density'] == density]
            avg_exploration_by_config = density_data.groupby('config_type')['final_exploration_rate'].mean()
            plt.plot(avg_exploration_by_config.index, avg_exploration_by_config.values, 
                    color=density_colors.get(density, 'gray'), 
                    label=f'Density {density}', linewidth=2, marker='D', markersize=6)
        
        plt.title('Impact of Obstacle Density')
        plt.xlabel('Config Type')
        plt.ylabel('Average Exploration Rate')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/time_series_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ“ æ™‚ç³»åˆ—åˆ†æå®Œäº†")
    
    def clustering_analysis(self, output_dir: str = "analysis_results"):
        """ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ"""
        print("=== ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æå®Ÿè¡Œä¸­ ===")
        
        # ç‰¹å¾´é‡ã‚’æº–å‚™
        features = ['final_exploration_rate', 'steps_taken', 'obstacle_density']
        if 'total_reward' in self.episode_data.columns:
            features.extend(['total_reward', 'avg_reward'])
        
        # æ¬ æå€¤ã‚’é™¤å»
        analysis_data = self.episode_data[features + ['config_type']].dropna()
        
        if len(analysis_data) < 10:
            print("âŒ åˆ†æã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(analysis_data[features])
        
        # PCAåˆ†æ
        pca = PCA(n_components=2)
        X_pca = pca.fit_transform(X_scaled)
        
        # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
        optimal_k = min(4, len(analysis_data['config_type'].unique()))
        kmeans = KMeans(n_clusters=optimal_k, random_state=42)
        clusters = kmeans.fit_predict(X_scaled)
        
        plt.figure(figsize=(15, 5))
        
        # 1. PCAã«ã‚ˆã‚‹æ¬¡å…ƒå‰Šæ¸›çµæœ
        plt.subplot(1, 3, 1)
        config_colors = {'A': 'blue', 'B': 'red', 'C': 'green', 'D': 'orange'}
        for config_type in analysis_data['config_type'].unique():
            mask = analysis_data['config_type'] == config_type
            plt.scatter(X_pca[mask, 0], X_pca[mask, 1], 
                       c=config_colors.get(config_type, 'gray'),
                       label=f'Config {config_type}', alpha=0.7, s=50)
        
        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')
        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')
        plt.title('PCA Analysis Results')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 2. Clustering Results
        plt.subplot(1, 3, 2)
        scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=clusters, cmap='viridis', alpha=0.7, s=50)
        plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], 
                   c='red', marker='x', s=200, linewidths=3, label='Centroids')
        plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})')
        plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})')
        plt.title('K-means Clustering')
        plt.colorbar(scatter)
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # 3. Feature Importance
        plt.subplot(1, 3, 3)
        feature_importance = np.abs(pca.components_[0])
        plt.barh(features, feature_importance)
        plt.xlabel('Importance in PC1')
        plt.title('Feature Importance')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/clustering_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°çµæœã‚’CSVã§ä¿å­˜
        analysis_data['cluster'] = clusters
        analysis_data['pc1'] = X_pca[:, 0]
        analysis_data['pc2'] = X_pca[:, 1]
        analysis_data.to_csv(f"{output_dir}/clustering_results.csv", index=False, encoding='utf-8')
        
        print("âœ“ ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æå®Œäº†")
    
    def generate_comprehensive_report(self, output_dir: str = "analysis_results"):
        """åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        print("=== åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ ===")
        
        report_path = f"{output_dir}/comprehensive_analysis_report.md"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# åŒ…æ‹¬çš„ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœè§£æãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"ç”Ÿæˆæ—¥æ™‚: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            # ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼
            f.write("## ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼\n\n")
            f.write(f"- ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {len(self.episode_data)}\n")
            f.write(f"- ç·ã‚¹ãƒ†ãƒƒãƒ—æ•°: {len(self.step_data)}\n")
            f.write(f"- Configç¨®é¡: {', '.join(sorted(self.episode_data['config_type'].unique()))}\n")
            f.write(f"- éšœå®³ç‰©å¯†åº¦: {', '.join(map(str, sorted(self.episode_data['obstacle_density'].unique())))}\n\n")
            
            # åŸºæœ¬çµ±è¨ˆ
            f.write("## åŸºæœ¬çµ±è¨ˆ\n\n")
            basic_stats = self.episode_data.groupby('config_type')['final_exploration_rate'].agg([
                'count', 'mean', 'std', 'min', 'max', 'median'
            ]).round(4)
            
            f.write("### Configåˆ¥æ¢æŸ»ç‡çµ±è¨ˆ\n\n")
            f.write("| Config | ã‚µãƒ³ãƒ—ãƒ«æ•° | å¹³å‡ | æ¨™æº–åå·® | æœ€å°å€¤ | æœ€å¤§å€¤ | ä¸­å¤®å€¤ |\n")
            f.write("|--------|-----------|------|----------|--------|--------|--------|\n")
            
            for config in basic_stats.index:
                stats = basic_stats.loc[config]
                f.write(f"| {config} | {stats['count']} | {stats['mean']:.4f} | "
                       f"{stats['std']:.4f} | {stats['min']:.4f} | {stats['max']:.4f} | {stats['median']:.4f} |\n")
            
            f.write("\n")
            
            # æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            f.write("## æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n\n")
            ranking = self.episode_data.groupby('config_type')['final_exploration_rate'].mean().sort_values(ascending=False)
            
            f.write("### æ¢æŸ»ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n\n")
            for i, (config, rate) in enumerate(ranking.items(), 1):
                f.write(f"{i}. **Config {config}**: {rate:.4f}\n")
            
            f.write("\n")
            
            # æ”¹å–„ææ¡ˆ
            f.write("## æ”¹å–„ææ¡ˆ\n\n")
            best_config = ranking.index[0]
            worst_config = ranking.index[-1]
            improvement_gap = ranking.iloc[0] - ranking.iloc[-1]
            
            f.write(f"- **æœ€é«˜æ€§èƒ½**: Config {best_config} ({ranking.iloc[0]:.4f})\n")
            f.write(f"- **æœ€ä½æ€§èƒ½**: Config {worst_config} ({ranking.iloc[-1]:.4f})\n")
            f.write(f"- **æ”¹å–„ä½™åœ°**: {improvement_gap:.4f} ({improvement_gap/ranking.iloc[-1]*100:.1f}%ã®å‘ä¸Šå¯èƒ½æ€§)\n\n")
            
            # éšœå®³ç‰©å¯†åº¦ã®å½±éŸ¿
            if len(self.episode_data['obstacle_density'].unique()) > 1:
                f.write("## éšœå®³ç‰©å¯†åº¦ã®å½±éŸ¿\n\n")
                density_impact = self.episode_data.groupby(['config_type', 'obstacle_density'])['final_exploration_rate'].mean().unstack()
                
                f.write("### ConfigÃ—éšœå®³ç‰©å¯†åº¦ã®æ¢æŸ»ç‡\n\n")
                f.write("| Config |")
                for density in sorted(density_impact.columns):
                    f.write(f" å¯†åº¦{density:.3f} |")
                f.write("\n|--------|")
                for _ in density_impact.columns:
                    f.write("----------|")
                f.write("\n")
                
                for config in density_impact.index:
                    f.write(f"| {config} |")
                    for density in sorted(density_impact.columns):
                        value = density_impact.loc[config, density]
                        if pd.notna(value):
                            f.write(f" {value:.4f} |")
                        else:
                            f.write(" N/A |")
                    f.write("\n")
                
                f.write("\n")
        
        print(f"âœ“ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆã‚’ {report_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def run_advanced_analysis(self, output_dir: str = "analysis_results"):
        """é«˜åº¦ãªè§£æã‚’å®Ÿè¡Œ"""
        print("ğŸ”¬ é«˜åº¦ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœè§£æã‚’é–‹å§‹ã—ã¾ã™\n")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‡¦ç†
        self.load_and_process_data()
        
        if self.episode_data.empty:
            print("âŒ è§£æå¯¾è±¡ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return
        
        # å„ç¨®åˆ†æã‚’å®Ÿè¡Œ
        self.statistical_analysis(output_dir)
        self.time_series_analysis(output_dir)
        self.clustering_analysis(output_dir)
        self.generate_comprehensive_report(output_dir)
        
        print(f"\nğŸ‰ é«˜åº¦ãªè§£æå®Œäº†ï¼çµæœã¯ {output_dir}/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
        print(f"ğŸ“Š æ™‚ç³»åˆ—åˆ†æ: {output_dir}/time_series_analysis.png")
        print(f"ğŸ” ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ: {output_dir}/clustering_analysis.png")
        print(f"ğŸ“ˆ çµ±è¨ˆæ¤œå®šçµæœ: {output_dir}/statistical_tests.csv")
        print(f"ğŸ“ åŒ…æ‹¬çš„ãƒ¬ãƒãƒ¼ãƒˆ: {output_dir}/comprehensive_analysis_report.md")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    analyzer = AdvancedAnalyzer()
    analyzer.run_advanced_analysis()


if __name__ == "__main__":
    main() 