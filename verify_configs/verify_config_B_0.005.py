#!/usr/bin/env python3
"""
Config_B æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (éšœå®³ç‰©å¯†åº¦: 0.005)
Systemå­¦ç¿’ãªã— + Swarmå­¦ç¿’ã‚ã‚Š
"""

import os
import sys
import json
import numpy as np
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def setup_verification_environment():
    """æ¤œè¨¼ç”¨ç’°å¢ƒè¨­å®š"""
    from params.simulation import SimulationParam
    
    sim_param = SimulationParam()
    
    # åŸºæœ¬è¨­å®š
    sim_param.episodeNum = 100
    sim_param.maxStepsPerEpisode = 200
    
    # ç’°å¢ƒè¨­å®š
    sim_param.environment.map.width = 200
    sim_param.environment.map.height = 100
    sim_param.environment.obstacle.probability = 0.005
    
    # æ¢æŸ»è¨­å®š
    sim_param.explore.robotNum = 20
    sim_param.explore.coordinate.x = 10.0
    sim_param.explore.coordinate.y = 10.0
    sim_param.explore.boundary.inner = 0.0
    sim_param.explore.boundary.outer = 20.0
    
    # ãƒ­ã‚°è¨­å®šï¼ˆGIFç”Ÿæˆæœ‰åŠ¹ï¼‰
    sim_param.robot_logging.save_robot_data = True
    sim_param.robot_logging.save_position = True
    sim_param.robot_logging.save_collision = True
    sim_param.robot_logging.sampling_rate = 1.0
    
    return sim_param

def setup_config_B_agent():
    """Config_Bç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š"""
    from params.agent import AgentParam
    from params.system_agent import SystemAgentParam
    from params.swarm_agent import SwarmAgentParam
    from params.learning import LearningParameter
    
    agent_param = AgentParam()
    
    # SystemAgentè¨­å®š
    system_param = SystemAgentParam()
    system_param.learningParameter = None
    system_param.branch_condition.branch_enabled = False
    system_param.integration_condition.integration_enabled = False
    agent_param.system_agent_param = system_param
    
    # SwarmAgentè¨­å®š
    swarm_param = SwarmAgentParam()
    swarm_param.isLearning = True
    swarm_param.learningParameter = LearningParameter(
        type="A2C",
        model=None,
        optimizer=None,
        gamma=0.99,
        learningLate=0.001,
        nStep=5
    )
    agent_param.swarm_agent_params = [swarm_param]
    
    return agent_param

def run_verification():
    """æ¤œè¨¼å®Ÿè¡Œ"""
    print("=== Config_B æ¤œè¨¼é–‹å§‹ (éšœå®³ç‰©å¯†åº¦: 0.005) ===")
    
    try:
        # 1. ç’°å¢ƒè¨­å®š
        print("1. ç’°å¢ƒè¨­å®šä¸­...")
        sim_param = setup_verification_environment()
        print("âœ“ ç’°å¢ƒè¨­å®šå®Œäº†")
        
        # 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
        print("2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šä¸­...")
        agent_param = setup_config_B_agent()
        print("âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šå®Œäº†")
        
        # 3. ç’°å¢ƒä½œæˆ
        print("3. ç’°å¢ƒä½œæˆä¸­...")
        from envs.env import Env
        env = Env(sim_param)
        print("âœ“ ç’°å¢ƒä½œæˆå®Œäº†")
        
        # 4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        print("4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆä¸­...")
        from agents.agent_factory import create_initial_agents
        system_agent, swarm_agents = create_initial_agents(env, agent_param)
        print(f"âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆå®Œäº† - SwarmAgents: {len(swarm_agents)}")
        
        # 5. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        print("5. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        model_path = "trained_models/config_b/swarm_agent_model_1.h5"
        if not os.path.exists(model_path):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
            return
        
        from keras.utils import custom_object_scope
        from models.swarm_actor_critic import SwarmActorCritic
        
        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥èª­ã¿è¾¼ã¿
        with custom_object_scope({'SwarmActorCritic': SwarmActorCritic}):
            from keras.models import load_model
            trained_model = load_model(model_path)
        
        # å„ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
        for swarm_id, agent in swarm_agents.items():
            agent.model = trained_model
            print(f"  âœ“ SwarmAgent {swarm_id} ã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šå®Œäº†")
        
        # 6. SystemAgentã‚’ç’°å¢ƒã«è¨­å®š
        print("6. SystemAgentã‚’ç’°å¢ƒã«è¨­å®šä¸­...")
        env.set_system_agent(system_agent)
        print("âœ“ SystemAgentè¨­å®šå®Œäº†")
        
        # çµæœä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = "verification_results/Config_B_obstacle_0.005"
        os.makedirs(output_dir, exist_ok=True)
        print(f"âœ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {output_dir}")
        
        # 7. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å®Ÿè¡Œ
        results = []
        for episode in range(sim_param.episodeNum):
            print(f"\n--- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode + 1}/{sim_param.episodeNum} ---")
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–‹å§‹
            env.start_episode(episode)
            state = env.reset()
            print(f"  ç’°å¢ƒãƒªã‚»ãƒƒãƒˆå®Œäº†")
            
            # GIFç”Ÿæˆã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
            env.capture_frame()
            
            episode_data = {
                'episode': episode + 1,
                'steps_to_target': None,
                'final_exploration_rate': 0.0,
                'steps_taken': 0,
                'step_details': []  # è©³ç´°ãªstepãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            }
            
            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            for step in range(sim_param.maxStepsPerEpisode):
                if step % 20 == 0:  # 20ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ­ã‚°
                    print(f"    ã‚¹ãƒ†ãƒƒãƒ— {step + 1}/{sim_param.maxStepsPerEpisode}")
                
                # SwarmAgentã®è¡Œå‹•å–å¾—
                swarm_actions = {}
                for swarm_id, agent in swarm_agents.items():
                    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¡Œå‹•ã‚’æ±ºå®š
                    swarm_observation = env.get_swarm_agent_observation(swarm_id)
                    action = agent.get_action(swarm_observation)
                    swarm_actions[swarm_id] = action
                
                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
                next_state, rewards, done, truncated, info = env.step(swarm_actions)
                
                # æ¢æŸ»ç‡ç¢ºèª
                exploration_rate = env.get_exploration_rate()
                episode_data['final_exploration_rate'] = exploration_rate
                episode_data['steps_taken'] = step + 1
                
                # è©³ç´°ãªstepãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
                step_detail = {
                    'step': step,
                    'exploration_rate': exploration_rate,
                    'reward': rewards if isinstance(rewards, (int, float)) else np.mean(list(rewards.values())) if rewards else 0.0,
                    'done': done,
                    'truncated': truncated
                }
                
                # ç’°å¢ƒã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
                if hasattr(env, 'get_exploration_info'):
                    exploration_info = env.get_exploration_info()
                    step_detail.update({
                        'explored_area': exploration_info.get('explored_area', 0),
                        'total_area': exploration_info.get('total_area', 0),
                        'new_explored_area': exploration_info.get('new_explored_area', 0)
                    })
                
                # è¡çªæƒ…å ±ã‚’å–å¾—
                if hasattr(env, 'get_collision_info'):
                    collision_info = env.get_collision_info()
                    step_detail.update({
                        'agent_collision_flag': collision_info.get('agent_collision_flag', 0),
                        'follower_collision_count': collision_info.get('follower_collision_count', 0)
                    })
                
                # ãƒ­ãƒœãƒƒãƒˆä½ç½®æƒ…å ±ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
                if hasattr(env, 'get_robot_positions') and step % 10 == 0:  # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    robot_positions = env.get_robot_positions()
                    step_detail['robot_positions'] = robot_positions
                
                episode_data['step_details'].append(step_detail)
                
                # ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
                if exploration_rate >= 0.8:
                    episode_data['steps_to_target'] = step + 1
                    print(f"    ç›®æ¨™é”æˆï¼ã‚¹ãƒ†ãƒƒãƒ— {step + 1}ã§80%æ¢æŸ»ã«åˆ°é”")
                    break
                
                if done or truncated:
                    print(f"    ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†ï¼ˆã‚¹ãƒ†ãƒƒãƒ— {step + 1}ï¼‰")
                    break
            
            results.append(episode_data)
            print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode + 1} å®Œäº† - æ¢æŸ»ç‡: {episode_data['final_exploration_rate']:.3f}")
            
            # GIFç”Ÿæˆã®ãŸã‚ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†å‡¦ç†
            env.end_episode(output_dir)
        
        # 8. çµæœé›†è¨ˆ
        print("\n=== çµæœé›†è¨ˆ ===")
        final_result = {
            'config': 'Config_B',
            'environment': {
                'map_size': f"{sim_param.environment.map.width}x{sim_param.environment.map.height}",
                'obstacle_density': sim_param.environment.obstacle.probability,
                'robot_count': sim_param.explore.robotNum
            },
            'episodes': results,
            'summary': {
                'total_episodes': len(results),
                'target_reached_episodes': len([r for r in results if r['steps_to_target'] is not None]),
                'average_exploration_rate': np.mean([r['final_exploration_rate'] for r in results]),
                'average_steps_taken': np.mean([r['steps_taken'] for r in results]),
                'std_exploration_rate': np.std([r['final_exploration_rate'] for r in results]),
                'std_steps_taken': np.std([r['steps_taken'] for r in results])
            }
        }
        
        # 9. çµæœä¿å­˜
        result_file = os.path.join(output_dir, "verification_result.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(final_result, f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ çµæœä¿å­˜å®Œäº†: {result_file}")
        
        # 10. çµæœè¡¨ç¤º
        print("\n=== æ¤œè¨¼çµæœ ===")
        print(f"ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {final_result['summary']['total_episodes']}")
        print(f"ç›®æ¨™é”æˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {final_result['summary']['target_reached_episodes']}")
        print(f"å¹³å‡æ¢æŸ»ç‡: {final_result['summary']['average_exploration_rate']:.3f} Â± {final_result['summary']['std_exploration_rate']:.3f}")
        print(f"å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {final_result['summary']['average_steps_taken']:.1f} Â± {final_result['summary']['std_steps_taken']:.1f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=== Config_B æ¤œè¨¼é–‹å§‹ (éšœå®³ç‰©å¯†åº¦: 0.005) ===")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now()}")
    
    success = run_verification()
    
    print(f"\nçµ‚äº†æ™‚åˆ»: {datetime.now()}")
    if success:
        print("ğŸ‰ æ¤œè¨¼ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("âŒ æ¤œè¨¼ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
