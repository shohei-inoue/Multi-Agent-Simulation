#!/usr/bin/env python3
"""
Config_B æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (éšœå®³ç‰©å¯†åº¦: 0.003)
Systemå­¦ç¿’ãªã— + Swarmå­¦ç¿’ã‚ã‚Š
"""

import os
import sys
import json
import numpy as np
from datetime import datetime
import matplotlib
matplotlib.use('Agg')  # éã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ç”¨

def convert_numpy_types(obj):
    """numpyå‹ã‚’Pythonå‹ã«å¤‰æ›ã—ã¦JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¯èƒ½ã«ã™ã‚‹"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def setup_verification_environment():
    """æ¤œè¨¼ç”¨ç’°å¢ƒè¨­å®š"""
    from params.simulation import SimulationParam
    
    sim_param = SimulationParam()
    
    # åŸºæœ¬è¨­å®š
    sim_param.episodeNum = 10
    sim_param.maxStepsPerEpisode = 50
    
    # ç’°å¢ƒè¨­å®š
    sim_param.environment.map.width = 200
    sim_param.environment.map.height = 100
    sim_param.environment.obstacle.probability = 0.003
    
    # æ¢æŸ»è¨­å®š
    sim_param.explore.robotNum = 20
    sim_param.explore.coordinate.x = 10.0
    sim_param.explore.coordinate.y = 10.0
    sim_param.explore.boundary.inner = 0.0
    sim_param.explore.boundary.outer = 20.0
    
    # ãƒ­ã‚°è¨­å®šï¼ˆGIFç”Ÿæˆæœ‰åŠ¹ï¼‰
    sim_param.robot_logging.save_robot_data = True
    sim_param.robot_logging.save_position = True
    sim_param.robot_logging.save_collision = True
    sim_param.robot_logging.sampling_rate = 1.0
    
    return sim_param

def setup_config_B_agent():
    """Config_Bç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š"""
    from params.agent import AgentParam
    from params.system_agent import SystemAgentParam
    from params.swarm_agent import SwarmAgentParam
    from params.learning import LearningParameter
    
    agent_param = AgentParam()
    
    # SystemAgentè¨­å®š
    system_param = SystemAgentParam()
    system_param.learningParameter = None
    system_param.branch_condition.branch_enabled = False
    system_param.integration_condition.integration_enabled = False
    agent_param.system_agent_param = system_param
    
    # SwarmAgentè¨­å®š
    swarm_param = SwarmAgentParam()
    swarm_param.isLearning = True
    swarm_param.learningParameter = LearningParameter(
        type="A2C",
        model="actor-critic",
        optimizer="adam",
        gamma=0.99,
        learningLate=0.001,
        nStep=5
    )
    agent_param.swarm_agent_params = [swarm_param]
    
    return agent_param

def run_verification():
    """æ¤œè¨¼å®Ÿè¡Œ"""
    print("=== Config_B æ¤œè¨¼é–‹å§‹ (éšœå®³ç‰©å¯†åº¦: 0.003) ===")
    
    try:
        # 1. ç’°å¢ƒè¨­å®š
        print("1. ç’°å¢ƒè¨­å®šä¸­...")
        sim_param = setup_verification_environment()
        print("âœ“ ç’°å¢ƒè¨­å®šå®Œäº†")
        
        # 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
        print("2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šä¸­...")
        agent_param = setup_config_B_agent()
        print("âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šå®Œäº†")
        
        # 3. ç’°å¢ƒä½œæˆ
        print("3. ç’°å¢ƒä½œæˆä¸­...")
        from envs.env import Env
        env = Env(sim_param)
        print("âœ“ ç’°å¢ƒä½œæˆå®Œäº†")
        
        # 4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        print("4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆä¸­...")
        from agents.agent_factory import create_initial_agents
        system_agent, swarm_agents = create_initial_agents(env, agent_param)
        print(f"âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆå®Œäº† - SwarmAgents: {len(swarm_agents)}")
        
        # 5. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        print("5. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        model_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "trained_models/config_b/swarm_agent_model_1.h5")
        if not os.path.exists(model_path):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_path}")
            return
        
        from keras.utils import custom_object_scope
        from models.swarm_actor_critic import SwarmActorCritic
        
        # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ç›´æ¥èª­ã¿è¾¼ã¿
        try:
            with custom_object_scope({'SwarmActorCritic': SwarmActorCritic}):
                from keras.models import load_model
                trained_model = load_model(model_path)
            
            # å„ã‚¹ã‚¦ã‚©ãƒ¼ãƒ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
            for swarm_id, agent in swarm_agents.items():
                agent.model = trained_model
                print(f"  âœ“ SwarmAgent {swarm_id} ã«å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šå®Œäº†")
        except Exception as e:
            print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            print("æ–°ã—ããƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¦å­¦ç¿’ãªã—ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™")
            # å­¦ç¿’ãªã—ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ
            for swarm_id, agent in swarm_agents.items():
                agent.isLearning = False
                agent.learningParameter = None
                print(f"  âœ“ SwarmAgent {swarm_id} ã‚’å­¦ç¿’ãªã—ãƒ¢ãƒ¼ãƒ‰ã«è¨­å®š")
        
        # 6. SystemAgentã‚’ç’°å¢ƒã«è¨­å®š
        print("6. SystemAgentã‚’ç’°å¢ƒã«è¨­å®šä¸­...")
        env.set_system_agent(system_agent)
        print("âœ“ SystemAgentè¨­å®šå®Œäº†")
        
        # çµæœä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = "verification_results/Config_B_obstacle_0.003"
        os.makedirs(output_dir, exist_ok=True)
        print(f"âœ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {output_dir}")
        
        # 7. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å®Ÿè¡Œ
        results = []
        for episode in range(sim_param.episodeNum):
            print(f"\n--- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode + 1}/{sim_param.episodeNum} ---")
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–‹å§‹æ™‚ã®çŠ¶æ…‹åˆæœŸåŒ–
            if episode > 0:  # 2ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç›®ä»¥é™
                print(f"  ğŸ”„ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–“çŠ¶æ…‹åˆæœŸåŒ–ä¸­...")
                
                # SystemAgentã®çŠ¶æ…‹ã‚’åˆæœŸåŒ–
                system_agent.next_swarm_id = 1  # ç¾¤IDã‚’ãƒªã‚»ãƒƒãƒˆ
                system_agent.current_swarm_count = 0  # ç¾¤æ•°ã‚’ãƒªã‚»ãƒƒãƒˆ
                system_agent.swarm_agents.clear()  # ç™»éŒ²ã•ã‚ŒãŸç¾¤ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ã‚¯ãƒªã‚¢
                
                # æ—¢å­˜ã®SwarmAgentã‚’ã‚¯ãƒªã‚¢
                swarm_agents.clear()
                
                # æ–°ã—ã„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰1ã¨åŒæ§˜ï¼‰
                from agents.agent_factory import create_initial_agents
                system_agent, swarm_agents = create_initial_agents(env, agent_param)
                
                # SystemAgentã‚’ç’°å¢ƒã«å†è¨­å®š
                env.set_system_agent(system_agent)
                
                print(f"  âœ“ çŠ¶æ…‹åˆæœŸåŒ–å®Œäº† - SwarmAgents: {len(swarm_agents)}")
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–‹å§‹
            env.start_episode(episode)
            state = env.reset()
            print(f"  ç’°å¢ƒãƒªã‚»ãƒƒãƒˆå®Œäº†")
            
            # GIFç”Ÿæˆã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
            env.capture_frame()
            
            episode_data = {
                'episode': episode + 1,
                'steps_to_target': None,
                'final_exploration_rate': 0.0,
                'steps_taken': 0,
                'step_details': []  # è©³ç´°ãªstepãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            }
            
            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            for step in range(sim_param.maxStepsPerEpisode):
                if step % 20 == 0:  # 20ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ­ã‚°
                    print(f"    ã‚¹ãƒ†ãƒƒãƒ— {step + 1}/{sim_param.maxStepsPerEpisode}")
                
                # å„SwarmAgentã®è¡Œå‹•å–å¾—ï¼ˆmain.pyã¨åŒæ§˜ã®é †åºï¼‰
                swarm_actions = {}
                for swarm_id, agent in swarm_agents.items():
                    # env.swarmsã‹ã‚‰è©²å½“ã™ã‚‹ç¾¤ã‚’æ¢ã™
                    swarm_exists = any(swarm.swarm_id == swarm_id for swarm in env.swarms)
                    if swarm_exists:  # å­˜åœ¨ã™ã‚‹ç¾¤ã®ã¿
                        # é©åˆ‡ãªçŠ¶æ…‹ã‚’å–å¾—ï¼ˆmain.pyã¨åŒæ§˜ï¼‰
                        swarm_observation = env.get_swarm_agent_observation(swarm_id)
                        action_tensor, action_dict = agent.get_action(swarm_observation)
                        swarm_actions[swarm_id] = action_dict
                    else:
                        if step == 0:
                            print(f"    Swarm {swarm_id} not found in env.swarms")
                
                # SystemAgentã®è¡Œå‹•å–å¾—ã¨å®Ÿè¡Œï¼ˆåˆ†å²ãƒ»çµ±åˆåˆ¤æ–­ï¼‰
                system_observation = env.get_system_agent_observation()
                system_action = system_agent.get_action(system_observation)
                
                # SystemAgentã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œï¼ˆåˆ†å²ãƒ»çµ±åˆå‡¦ç†ï¼‰
                if system_action and isinstance(system_action, dict):
                    action_type = system_action.get('action_type', 0)
                    target_swarm_id = system_action.get('target_swarm_id', 0)
                    
                    if action_type == 1:  # åˆ†å²
                        print(f"    ğŸ”€ åˆ†å²å‡¦ç†å®Ÿè¡Œ: swarm {target_swarm_id}")
                        # åˆ†å²å‡¦ç†ã‚’å®Ÿè¡Œ
                        system_agent._execute_branch({
                            'swarm_id': target_swarm_id,
                            'valid_directions': [0, 45, 90, 135, 180, 225, 270, 315]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æ–¹å‘
                        })
                    elif action_type == 2:  # çµ±åˆ
                        print(f"    ğŸ”— çµ±åˆå‡¦ç†å®Ÿè¡Œ: swarm {target_swarm_id}")
                        # çµ±åˆå‡¦ç†ã‚’å®Ÿè¡Œ
                        system_agent._execute_integration({
                            'swarm_id': target_swarm_id
                        })
                
                # ç’°å¢ƒã®ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
                next_state, rewards, done, truncated, info = env.step(swarm_actions)
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆGIFç”Ÿæˆç”¨ï¼‰
                try:
                    env.capture_frame()
                except Exception as e:
                    print(f"    ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")
                
                # æ¢æŸ»ç‡ç¢ºèª
                exploration_rate = env.get_exploration_rate()
                episode_data['final_exploration_rate'] = exploration_rate
                episode_data['steps_taken'] = step + 1
                
                # è©³ç´°ãªstepãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
                step_detail = {
                    'step': step,
                    'exploration_rate': exploration_rate,
                    'reward': rewards if isinstance(rewards, (int, float)) else np.mean(list(rewards.values())) if rewards else 0.0,
                    'done': done,
                    'truncated': truncated
                }
                
                # ç’°å¢ƒã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
                if hasattr(env, 'get_exploration_info'):
                    exploration_info = env.get_exploration_info()
                    step_detail.update({
                        'explored_area': exploration_info.get('explored_area', 0),
                        'total_area': exploration_info.get('total_area', 0),
                        'new_explored_area': exploration_info.get('new_explored_area', 0)
                    })
                
                # è¡çªæƒ…å ±ã‚’å–å¾—
                if hasattr(env, 'get_collision_info'):
                    collision_info = env.get_collision_info()
                    step_detail.update({
                        'agent_collision_flag': collision_info.get('agent_collision_flag', 0),
                        'follower_collision_count': collision_info.get('follower_collision_count', 0)
                    })
                
                # ãƒ­ãƒœãƒƒãƒˆä½ç½®æƒ…å ±ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
                if hasattr(env, 'get_robot_positions') and step % 10 == 0:  # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    robot_positions = env.get_robot_positions()
                    step_detail['robot_positions'] = robot_positions
                
                episode_data['step_details'].append(step_detail)
                
                # ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
                if exploration_rate >= 0.8:
                    episode_data['steps_to_target'] = step + 1
                    print(f"    ç›®æ¨™é”æˆï¼ã‚¹ãƒ†ãƒƒãƒ— {step + 1}ã§80%æ¢æŸ»ã«åˆ°é”")
                    break
                
                if done or truncated:
                    print(f"    ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†ï¼ˆã‚¹ãƒ†ãƒƒãƒ— {step + 1}ï¼‰")
                    break
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†æ™‚ã«GIFä¿å­˜
            try:
                env.end_episode(output_dir)
                print(f"    GIFä¿å­˜å®Œäº†")
            except Exception as e:
                print(f"    GIFä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")
            
            results.append(episode_data)
            print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode + 1} å®Œäº† - æ¢æŸ»ç‡: {episode_data['final_exploration_rate']:.3f}")
        
        # 8. çµæœé›†è¨ˆ
        print("\n=== çµæœé›†è¨ˆ ===")
        final_result = {
            'config': 'Config_B',
            'environment': {
                'map_size': f"{sim_param.environment.map.width}x{sim_param.environment.map.height}",
                'obstacle_density': sim_param.environment.obstacle.probability,
                'robot_count': sim_param.explore.robotNum
            },
            'episodes': results,
            'summary': {
                'total_episodes': len(results),
                'target_reached_episodes': len([r for r in results if r['steps_to_target'] is not None]),
                'average_exploration_rate': np.mean([r['final_exploration_rate'] for r in results]),
                'average_steps_taken': np.mean([r['steps_taken'] for r in results]),
                'std_exploration_rate': np.std([r['final_exploration_rate'] for r in results]),
                'std_steps_taken': np.std([r['steps_taken'] for r in results])
            }
        }
        
        # 9. çµæœä¿å­˜
        result_file = os.path.join(output_dir, "verification_result.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(convert_numpy_types(final_result), f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ çµæœä¿å­˜å®Œäº†: {result_file}")
        
        # 10. çµæœè¡¨ç¤º
        print("\n=== æ¤œè¨¼çµæœ ===")
        print(f"ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {final_result['summary']['total_episodes']}")
        print(f"ç›®æ¨™é”æˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {final_result['summary']['target_reached_episodes']}")
        print(f"å¹³å‡æ¢æŸ»ç‡: {final_result['summary']['average_exploration_rate']:.3f} Â± {final_result['summary']['std_exploration_rate']:.3f}")
        print(f"å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {final_result['summary']['average_steps_taken']:.1f} Â± {final_result['summary']['std_steps_taken']:.1f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=== Config_B æ¤œè¨¼é–‹å§‹ (éšœå®³ç‰©å¯†åº¦: 0.003) ===")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now()}")
    
    success = run_verification()
    
    print(f"\nçµ‚äº†æ™‚åˆ»: {datetime.now()}")
    if success:
        print("ğŸ‰ æ¤œè¨¼ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("âŒ æ¤œè¨¼ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
