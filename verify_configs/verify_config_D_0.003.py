#!/usr/bin/env python3
"""
Config_D æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ (éšœå®³ç‰©å¯†åº¦: 0.003)
Systemå­¦ç¿’ã‚ã‚Š + Swarmå­¦ç¿’ã‚ã‚Š + åˆ†å²ãƒ»çµ±åˆã‚ã‚Š
"""

import os
import sys
import json
import numpy as np
from datetime import datetime
import matplotlib
matplotlib.use('Agg')  # éã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’ä½¿ç”¨

def convert_numpy_types(obj):
    """numpyå‹ã‚’Pythonå‹ã«å¤‰æ›ã—ã¦JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¯èƒ½ã«ã™ã‚‹"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    else:
        return obj

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def setup_verification_environment():
    """æ¤œè¨¼ç”¨ç’°å¢ƒè¨­å®š"""
    from params.simulation import SimulationParam
    
    sim_param = SimulationParam()
    
    # åŸºæœ¬è¨­å®š
    sim_param.episodeNum = 100
    sim_param.maxStepsPerEpisode = 200
    
    # ç’°å¢ƒè¨­å®š
    sim_param.environment.map.width = 200
    sim_param.environment.map.height = 100
    sim_param.environment.obstacle.probability = 0.003
    
    # æ¢æŸ»è¨­å®š
    sim_param.explore.robotNum = 20
    sim_param.explore.coordinate.x = 10.0
    sim_param.explore.coordinate.y = 10.0
    sim_param.explore.boundary.inner = 0.0
    sim_param.explore.boundary.outer = 20.0
    
    # ãƒ­ã‚°è¨­å®šï¼ˆGIFç”Ÿæˆæœ‰åŠ¹ï¼‰
    sim_param.robot_logging.save_robot_data = True
    sim_param.robot_logging.save_position = True
    sim_param.robot_logging.save_collision = True
    sim_param.robot_logging.sampling_rate = 1.0
    
    return sim_param

def setup_config_D_agent():
    """Config_Dç”¨ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š"""
    from params.agent import AgentParam
    from params.system_agent import SystemAgentParam
    from params.swarm_agent import SwarmAgentParam
    from params.learning import LearningParameter
    
    agent_param = AgentParam()
    
    # SystemAgentè¨­å®š
    system_param = SystemAgentParam()
    system_param.learningParameter = LearningParameter(
        type="A2C",
        model=None,
        optimizer=None,
        gamma=0.99,
        learningLate=0.001,
        nStep=5
    )
    system_param.branch_condition.branch_enabled = True
    system_param.integration_condition.integration_enabled = True
    agent_param.system_agent_param = system_param
    
    # SwarmAgentè¨­å®š
    swarm_param = SwarmAgentParam()
    swarm_param.isLearning = True
    swarm_param.learningParameter = LearningParameter(
        type="A2C",
        model=None,
        optimizer=None,
        gamma=0.99,
        learningLate=0.001,
        nStep=5
    )
    agent_param.swarm_agent_params = [swarm_param]
    
    return agent_param

def run_verification():
    """æ¤œè¨¼å®Ÿè¡Œ"""
    print("=== Config_D æ¤œè¨¼é–‹å§‹ (éšœå®³ç‰©å¯†åº¦: 0.003) ===")
    
    try:
        # 1. ç’°å¢ƒè¨­å®š
        print("1. ç’°å¢ƒè¨­å®šä¸­...")
        sim_param = setup_verification_environment()
        print("âœ“ ç’°å¢ƒè¨­å®šå®Œäº†")
        
        # 2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®š
        print("2. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šä¸­...")
        agent_param = setup_config_D_agent()
        print("âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šå®Œäº†")
        
        # 3. ç’°å¢ƒä½œæˆ
        print("3. ç’°å¢ƒä½œæˆä¸­...")
        from envs.env import Env
        env = Env(sim_param)
        print("âœ“ ç’°å¢ƒä½œæˆå®Œäº†")
        
        # 4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
        print("4. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆä¸­...")
        from agents.agent_factory import create_initial_agents
        system_agent, swarm_agents = create_initial_agents(env, agent_param)
        print(f"âœ“ ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆå®Œäº† - SwarmAgents: {len(swarm_agents)}")
        
        # 5. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        print("5. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­...")
        # SystemAgentãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        system_model_path = "trained_models/system_agent_model.h5"
        if os.path.exists(system_model_path):
            system_agent.load_model(system_model_path)
            print(f"  âœ“ SystemAgent ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
        else:
            print(f"  âš ï¸ SystemAgent ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {{system_model_path}}")
        
        # SwarmAgentãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        for swarm_id, agent in swarm_agents.items():
            model_path = f"trained_models/swarm_agent_model_{{swarm_id}}.h5"
            if os.path.exists(model_path):
                agent.load_model(model_path)
                print(f"  âœ“ SwarmAgent {{swarm_id}} ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")
            else:
                print(f"  âš ï¸ SwarmAgent {{swarm_id}} ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {{model_path}}")
        
        # 6. SystemAgentã‚’ç’°å¢ƒã«è¨­å®š
        print("6. SystemAgentã‚’ç’°å¢ƒã«è¨­å®šä¸­...")
        env.set_system_agent(system_agent)
        print("âœ“ SystemAgentè¨­å®šå®Œäº†")
        
        # çµæœä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_dir = "verification_results/Config_D_obstacle_0.003"
        os.makedirs(output_dir, exist_ok=True)
        print(f"âœ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {output_dir}")
        
        # 7. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å®Ÿè¡Œ
        results = []
        for episode in range(sim_param.episodeNum):
            print(f"\n--- ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode + 1}/{sim_param.episodeNum} ---")
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰é–‹å§‹
            env.start_episode(episode)
            state = env.reset()
            print(f"  ç’°å¢ƒãƒªã‚»ãƒƒãƒˆå®Œäº†")
            
            # GIFç”Ÿæˆã®ãŸã‚ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
            env.capture_frame()
            
            episode_data = {
                'episode': episode + 1,
                'steps_to_target': None,
                'final_exploration_rate': 0.0,
                'steps_taken': 0,
                'step_details': []  # è©³ç´°ãªstepãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
            }
            
            # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
            for step in range(sim_param.maxStepsPerEpisode):
                if step % 20 == 0:  # 20ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ãƒ­ã‚°
                    print(f"    ã‚¹ãƒ†ãƒƒãƒ— {step + 1}/{sim_param.maxStepsPerEpisode}")
                
                # SystemAgentã®è¡Œå‹•å–å¾—ï¼ˆåˆ†å²ãƒ»çµ±åˆåˆ¤æ–­ï¼‰
                system_observation = env.get_system_agent_observation()
                system_action = system_agent.get_action(system_observation)
                
                # SwarmAgentã®è¡Œå‹•å–å¾—
                swarm_actions = {}
                for swarm_id, agent in swarm_agents.items():
                    # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¡Œå‹•ã‚’æ±ºå®š
                    swarm_observation = env.get_swarm_agent_observation(swarm_id)
                    action_tensor, action_dict = agent.get_action(swarm_observation)
                    swarm_actions[swarm_id] = action_dict
                
                # åˆ†å²å¾Œã«æ–°ã—ã„SwarmAgentãŒå¿…è¦ã‹ãƒã‚§ãƒƒã‚¯
                current_swarm_ids = [swarm.swarm_id for swarm in env.swarms]
                for swarm_id in current_swarm_ids:
                    if swarm_id not in swarm_agents:
                        print(f"æ–°ã—ã„SwarmAgent {swarm_id} ã‚’ä½œæˆä¸­...")
                        # æ–°ã—ã„SwarmAgentã‚’ä½œæˆ
                        from agents.agent_factory import create_swarm_agent
                        new_swarm_agent = create_swarm_agent(
                            env=env,
                            param=agent_param.swarm_agent_params[0],  # åŒã˜ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
                            system_agent=system_agent,
                            swarm_id=swarm_id
                        )
                        swarm_agents[swarm_id] = new_swarm_agent
                        print(f"âœ“ SwarmAgent {swarm_id} ä½œæˆå®Œäº†")
                
                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œï¼ˆactionsã‚’çµ±åˆï¼‰
                all_actions = {**swarm_actions}  # swarm_actionsã‚’ã‚³ãƒ”ãƒ¼
                if system_action and isinstance(system_action, dict):  # system_actionãŒè¾æ›¸ã®å ´åˆã®ã¿è¿½åŠ 
                    all_actions.update(system_action)
                next_state, rewards, done, truncated, info = env.step(all_actions)
                
                # awahãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆæ˜ç¤ºçš„ã«å‘¼ã³å‡ºã—ï¼‰
                try:
                    env.capture_frame()
                except Exception as e:
                    print(f"    ãƒ•ãƒ¬ãƒ¼ãƒ ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")
                
                # æ¢æŸ»ç‡ç¢ºèª
                exploration_rate = env.get_exploration_rate()
                episode_data['final_exploration_rate'] = exploration_rate
                episode_data['steps_taken'] = step + 1
                
                # è©³ç´°ãªstepãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
                step_detail = {
                    'step': step,
                    'exploration_rate': exploration_rate,
                    'reward': rewards if isinstance(rewards, (int, float)) else np.mean(list(rewards.values())) if rewards else 0.0,
                    'done': done,
                    'truncated': truncated
                }
                
                # ç’°å¢ƒã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
                if hasattr(env, 'get_exploration_info'):
                    exploration_info = env.get_exploration_info()
                    step_detail.update({
                        'explored_area': exploration_info.get('explored_area', 0),
                        'total_area': exploration_info.get('total_area', 0),
                        'new_explored_area': exploration_info.get('new_explored_area', 0)
                    })
                
                # è¡çªæƒ…å ±ã‚’å–å¾—
                if hasattr(env, 'get_collision_info'):
                    collision_info = env.get_collision_info()
                    step_detail.update({
                        'agent_collision_flag': collision_info.get('agent_collision_flag', 0),
                        'follower_collision_count': collision_info.get('follower_collision_count', 0)
                    })
                
                # ãƒ­ãƒœãƒƒãƒˆä½ç½®æƒ…å ±ã‚’å–å¾—ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰
                if hasattr(env, 'get_robot_positions') and step % 10 == 0:  # 10ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                    robot_positions = env.get_robot_positions()
                    step_detail['robot_positions'] = robot_positions
                
                episode_data['step_details'].append(step_detail)
                
                # ç›®æ¨™é”æˆãƒã‚§ãƒƒã‚¯
                if exploration_rate >= 0.8:
                    episode_data['steps_to_target'] = step + 1
                    print(f"    ç›®æ¨™é”æˆï¼ã‚¹ãƒ†ãƒƒãƒ— {step + 1}ã§80%æ¢æŸ»ã«åˆ°é”")
                    break
                
                if done or truncated:
                    print(f"    ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†ï¼ˆã‚¹ãƒ†ãƒƒãƒ— {step + 1}ï¼‰")
                    break
            
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰çµ‚äº†æ™‚ã«GIFä¿å­˜
            try:
                env.end_episode(output_dir)
                print(f"    GIFä¿å­˜å®Œäº†")
            except Exception as e:
                print(f"    GIFä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–ï¼‰: {e}")
            
            results.append(episode_data)
            print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ {episode + 1} å®Œäº† - æ¢æŸ»ç‡: {episode_data['final_exploration_rate']:.3f}")
        
        # 8. çµæœé›†è¨ˆ
        print("\n=== çµæœé›†è¨ˆ ===")
        final_result = {
            'config': 'Config_D',
            'environment': {
                'map_size': f"{sim_param.environment.map.width}x{sim_param.environment.map.height}",
                'obstacle_density': sim_param.environment.obstacle.probability,
                'robot_count': sim_param.explore.robotNum
            },
            'episodes': results,
            'summary': {
                'total_episodes': len(results),
                'target_reached_episodes': len([r for r in results if r['steps_to_target'] is not None]),
                'average_exploration_rate': np.mean([r['final_exploration_rate'] for r in results]),
                'average_steps_taken': np.mean([r['steps_taken'] for r in results]),
                'std_exploration_rate': np.std([r['final_exploration_rate'] for r in results]),
                'std_steps_taken': np.std([r['steps_taken'] for r in results])
            }
        }
        
        # 9. çµæœä¿å­˜
        result_file = os.path.join(output_dir, "verification_result.json")
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(convert_numpy_types(final_result), f, indent=2, ensure_ascii=False)
        
        print(f"âœ“ çµæœä¿å­˜å®Œäº†: {result_file}")
        
        # 10. çµæœè¡¨ç¤º
        print("\n=== æ¤œè¨¼çµæœ ===")
        print(f"ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {final_result['summary']['total_episodes']}")
        print(f"ç›®æ¨™é”æˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {final_result['summary']['target_reached_episodes']}")
        print(f"å¹³å‡æ¢æŸ»ç‡: {final_result['summary']['average_exploration_rate']:.3f} Â± {final_result['summary']['std_exploration_rate']:.3f}")
        print(f"å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {final_result['summary']['average_steps_taken']:.1f} Â± {final_result['summary']['std_steps_taken']:.1f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("=== Config_D æ¤œè¨¼é–‹å§‹ (éšœå®³ç‰©å¯†åº¦: 0.003) ===")
    print(f"é–‹å§‹æ™‚åˆ»: {datetime.now()}")
    
    success = run_verification()
    
    print(f"\nçµ‚äº†æ™‚åˆ»: {datetime.now()}")
    if success:
        print("ğŸ‰ æ¤œè¨¼ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸï¼")
    else:
        print("âŒ æ¤œè¨¼ãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")
        sys.exit(1)
